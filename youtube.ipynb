{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e008c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "url = \"data\"\n",
    "loader = YoutubeLoader.from_youtube_url(url, add_video_info=False)\n",
    "docs = loader.load()\n",
    "doc = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb9aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import  RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "chunks = text_splitter.split_text(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41d689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (SystemMessagePromptTemplate, \n",
    "                                    HumanMessagePromptTemplate,\n",
    "                                    ChatPromptTemplate)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "system = SystemMessagePromptTemplate.from_template(\"\"\"You are helpful AI assistant who creates summarization based on the provided context.\"\"\")\n",
    "prompt = \"\"\"Create a short summarization of the provided context!\n",
    "            ### Context:\n",
    "            {context}\n",
    "\n",
    "            ### Answer:\"\"\"\n",
    "\n",
    "llm = ChatOllama(model='data', base_url='data')\n",
    "prompt = HumanMessagePromptTemplate.from_template(prompt)\n",
    "messages = [system, prompt]\n",
    "template = ChatPromptTemplate(messages)\n",
    "qna_chain = template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d57954",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = []\n",
    "for chunk in chunks:\n",
    "    sum = qna_chain.invoke({'context':chunk})\n",
    "    sums.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de123b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_join = \". \".join([sum.split('\\n\\n')[-1] for sum in sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffabb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qna_chain.invoke({'context':sums_join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c306742",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
